{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python2.7\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time as time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from check_files import path_check\n",
    "from predictor import Predictor\n",
    "\n",
    "def train_nn():\n",
    "\n",
    "    default_cleaned_dir = './data/cleaned/'\n",
    "    cleaned_directory = raw_input(\"Enter cleaned data directory ({0}):\".\n",
    "                                  format(default_cleaned_dir)) or default_cleaned_dir\n",
    "    # cleaned_directory = default_cleaned_dir\n",
    "\n",
    "    wf_num = 7\n",
    "    prefix = 'train'\n",
    "    error = np.zeros(wf_num)\n",
    "    trainRatio = 0.8\n",
    "    error_sum = 0\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for num in range(1, wf_num+1):\n",
    "        wf = np.loadtxt(cleaned_directory+'{0}_wf{1}.csv'.format(prefix, num), delimiter=',')\n",
    "\n",
    "        data = wf\n",
    "        np.random.shuffle(data)\n",
    "\n",
    "        dataTrain = data[:int(trainRatio*data.shape[0]),:]\n",
    "        dataTrainX = dataTrain[:,:-1]\n",
    "        dataTrainX = preprocessing.scale(dataTrainX)\n",
    "        dataTrainY = dataTrain[:,-1]\n",
    "\n",
    "        dataTest = data [int(trainRatio*data.shape[0]):,:]\n",
    "        dataTestX = dataTest[:,:-1]\n",
    "        dataTestX = preprocessing.scale(dataTestX)\n",
    "        dataTestY = dataTest[:,-1]\n",
    "\n",
    "        assert dataTrain.shape[0]+dataTest.shape[0] == data.shape[0]\n",
    "\n",
    "        hidden_layer_sizes = (10,5)\n",
    "        learning_rate_init = 0.001\n",
    "        # activationRange = ['logistic', 'tanh', 'relu']\n",
    "        activation = 'logistic'\n",
    "\n",
    "        MLPR = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                            learning_rate_init = learning_rate_init, activation = activation)\n",
    "\n",
    "        MLPR.fit(dataTrainX, dataTrainY)\n",
    "        errorTest = dataTestY - MLPR.predict(dataTestX)\n",
    "        error_sum += np.square(errorTest).sum()\n",
    "        MSE = np.sqrt(np.square(errorTest).sum()/errorTest.shape[0])\n",
    "        print 'MSE for wf{0}: {1}'.format(num, MSE)\n",
    "\n",
    "    MSE_all = np.sqrt(error_sum/errorTest.shape[0]/wf_num)\n",
    "    print 'MSE for all: {0}'.format(MSE_all)\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end -start\n",
    "    minutes, seconds = divmod(elapsed, 60)\n",
    "    \n",
    "    print 'Done. Time = {:0>1}m {:05.2f}s.'.format(int(minutes), seconds)\n",
    "    \n",
    "def train_nn2():\n",
    "    \"\"\"\n",
    "    Train the nerual network with cleaned data.\n",
    "    Data is first normalized, and then trained with \n",
    "    predictor class from Hongshan.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    default_cleaned_dir = './data/cleaned/'\n",
    "    cleaned_directory = raw_input(\"Enter cleaned data directory ({0}):\".\n",
    "                                  format(default_cleaned_dir)) or default_cleaned_dir\n",
    "    # cleaned_directory = default_cleaned_dir\n",
    "\n",
    "    wf_num = 7\n",
    "    prefix = 'train'\n",
    "    error = np.zeros(wf_num)\n",
    "    trainRatio = 0.8\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    for num in range(1, wf_num+1):\n",
    "        wf = np.loadtxt(cleaned_directory+'{0}_wf{1}.csv'.format(prefix, num), delimiter=',')\n",
    "            \n",
    "        dataX = wf[:,:-1]\n",
    "        dataX = preprocessing.scale(dataX)\n",
    "        dataY = wf[:,-1]\n",
    "        dataY = dataY[...,None]\n",
    "        data = np.append(dataX,dataY,axis=1)\n",
    "        np.random.shuffle(data)\n",
    "        \n",
    "        print \"For wf{0}\".format(num)\n",
    "        wfpredictor = Predictor(shape = [17, 10, 5, 1], \n",
    "                                path = cleaned_directory,\n",
    "                                name = '{0}_wf{1}.csv'.format(prefix, num),\n",
    "                                train_num = int(trainRatio*data.shape[0]))\n",
    "        wfpredictor.train(num_epoch=2, batch_size=20)\n",
    "        error[num -1] = wfpredictor.current_error\n",
    "        \n",
    "    size_test = data.shape[0] - int(trainRatio*data.shape[0])\n",
    "    error_sum = (np.square(error)*size_test).sum()\n",
    "    MSE_all = np.sqrt(error_sum/size_test/wf_num)\n",
    "    print 'MSE for all: {0}'.format(MSE_all)\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed = end -start\n",
    "    minutes, seconds = divmod(elapsed, 60)\n",
    "    \n",
    "    print 'Done. Time = {:0>1}m {:05.2f}s.'.format(int(minutes), seconds)\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    train_nn()\n",
    "    train_nn2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
